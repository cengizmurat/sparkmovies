{"paragraphs":[{"text":"import scala.util.parsing.json.JSON\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\nimport scala.math._\n\ncase class Feels(\n                   id: Int,\n                   positivity: Float,\n                   subjectivity: Float\n                )\n\ncase class Movie(\n                    id: Option[Double],\n                    title: Option[String],\n                    rating: Option[Double],\n                    release: Option[Int],\n                    author: Option[String],\n                    actors: Option[Seq[String]],\n                    genres: Option[Seq[String]],\n                    country: Option[String],\n                    reviews: Option[Seq[String]]\n                    //feels: Option[Feels]\n                )\n\ndef parseJSON(s: String): Map[String, Any] = JSON.parseFull(s).get.asInstanceOf[Map[String, Any]]\n\ndef parseMovie(s : String) : Movie =  {\n    val json = parseJSON(s)\n    val id = json(\"id\")\n    val title = json(\"title\")\n    val rating = json(\"rating\").asInstanceOf[Double]\n    val release = json(\"release\").asInstanceOf[Option[Int]]\n    val author = json(\"author\").asInstanceOf[Option[String]]\n    val actors = json(\"actors\").asInstanceOf[Option[Seq[String]]]\n    val genres = json(\"genres\").asInstanceOf[Option[Seq[String]]]\n    val country = json(\"country\").asInstanceOf[Option[String]]\n    val reviews = json(\"reviews\").asInstanceOf[Option[Seq[String]]]\n    Movie(\n            id match {\n                case Some(x) => Some(x)\n                case None => None\n                },\n            title match {\n                case Some(x) => Some(x)\n                case None => None\n            },\n            json(\"title\").asInstanceOf[Option[String]],\n            json(\"rating\").asInstanceOf[Double],\n            json(\"release\").asInstanceOf[Option[Int]],\n            json(\"author\").asInstanceOf[Option[String]],\n            json(\"actors\").asInstanceOf[Option[Seq[String]]],\n            json(\"genres\").asInstanceOf[Option[Seq[String]]],\n            json(\"country\").asInstanceOf[Option[String]],\n            json(\"reviews\").asInstanceOf[Option[Seq[String]]]\n        )\n}\n\nval path = \"/home/muratcengiz/Documents/spark/sparkmovies/data/movies.txt\"\nval linesRDD = sc.textFile(path)\n\ncase class Year_Rating(\n                    rating: Double,\n                    release: Int\n                )\n\nval movies = linesRDD.map(parseMovie)\n\n/*\nval year_rating = linesRDD.map(parseJSON).map(x => (x.get(\"rating\"), x.get(\"release\").asInstanceOf[Option[Double]])).groupBy(_._2).map(x => (x._1, x._2.map(_._1.asInstanceOf[Option[Double]]).foldLeft(0.0){\n        (acc, num) => acc + num.get\n    }/x._2.size)).map(x => Year_Rating(x._2, x._1.get.toInt))\n    */\nmovies.toDF().registerTempTable(\"movies\")","user":"anonymous","dateUpdated":"2017-07-10T22:30:13+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1499710469368_-429902698","id":"20170710-201429_509200812","dateCreated":"2017-07-10T20:14:29+0200","dateStarted":"2017-07-10T22:30:09+0200","dateFinished":"2017-07-10T22:22:08+0200","status":"ABORT","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:448"},{"text":"%sql \nselect title, rating\nfrom movies\norder by rating","user":"anonymous","dateUpdated":"2017-07-10T22:13:41+0200","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"release","index":1,"aggr":"sum"}],"groups":[],"values":[{"name":"rating","index":0,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.ClassCastException: java.lang.Double cannot be cast to scala.Option\n\tat $line1326661566445.$read$$iw$$iw$$iw$$iw$$iw$$iw$$$$$af5f7778a759937f8a22fc344e12a0$$$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.parseMovie(<console>:249)\n\tat $line1326661566449.$read$$iw$$iw$$iw$$iw$$iw$$iw$$$$$cce78f6fcec4b21a1691468c6579fe7c$$$$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(<console>:254)\n\tat $line1326661566449.$read$$iw$$iw$$iw$$iw$$iw$$iw$$$$$cce78f6fcec4b21a1691468c6579fe7c$$$$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(<console>:254)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:409)\n\tat scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31)\n\tat org.spark_project.guava.collect.Ordering.leastOf(Ordering.java:658)\n\tat org.apache.spark.util.collection.Utils$.takeOrdered(Utils.scala:37)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1422)\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1$$anonfun$30.apply(RDD.scala:1419)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1499710732163_1725443671","id":"20170710-201852_2089891989","dateCreated":"2017-07-10T20:18:52+0200","dateStarted":"2017-07-10T22:13:43+0200","dateFinished":"2017-07-10T22:13:44+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:449"},{"text":"%sql\n","user":"anonymous","dateUpdated":"2017-07-10T21:40:58+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1499715658311_-643741377","id":"20170710-214058_1297871589","dateCreated":"2017-07-10T21:40:58+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:450"}],"name":"zeppelin_scala","id":"2CPZ8UKRM","angularObjects":{"2CPBFSWN4:shared_process":[],"2CMWXUFHZ:shared_process":[],"2CPTG68TK:shared_process":[],"2CPV8C8N1:shared_process":[],"2CMFEWHPJ:shared_process":[],"2CMHPU2A6:shared_process":[],"2CQBGYBHV:shared_process":[],"2CQ3YPTVY:shared_process":[],"2CMJVQV61:shared_process":[],"2CP8WM288:shared_process":[],"2CNQWHPJ2:shared_process":[],"2CQ9HSUWP:shared_process":[],"2CNCDZY41:shared_process":[],"2CPZS44RB:shared_process":[],"2CQCVH4RQ:shared_process":[],"2CM1J4FUN:shared_process":[],"2CKS5ZWMG:shared_process":[],"2CNEKH2DB:shared_process":[],"2CNRAWUBX:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}